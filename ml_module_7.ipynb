{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Theoretical"
      ],
      "metadata": {
        "id": "7vxKOodPp0F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1.What is a Decision Tree, and how does it work?\n",
        "Ans:-A decision tree is a supervised machine learning algorithm used for both classification and regression tasks. It works by recursively partitioning the data into subsets based on the values of different features, creating a tree-like structure.\n",
        "\n",
        "# Here's a breakdown of how it works:\n",
        "\n",
        "1. Root Node: The tree starts with a root node representing the entire dataset.\n",
        "\n",
        "2. Feature Selection: At each node, the algorithm selects the \"best\" feature to split the data based on a criterion (e.g., Gini impurity, information gain, or entropy). The goal is to create subsets that are as pure as possible (contain mostly instances of a single class).\n",
        "\n",
        "3. Splitting: The selected feature is used to split the data into branches, each representing a subset with specific values of the feature.\n",
        "\n",
        "4. Recursion: Steps 2 and 3 are repeated recursively for each branch until a stopping criterion is met. This criterion could be a maximum tree depth, a minimum number of samples in a node, or a minimum impurity decrease.\n",
        "\n",
        "5. Leaf Nodes:  The terminal nodes of the tree are called leaf nodes. Each leaf node represents a prediction. For classification, the leaf node assigns the class label that is most frequent in the subset it represents. For regression, it predicts the average value of the target variable in the subset.\n",
        "\n",
        "6. Prediction: To predict the class label or value for a new instance, the instance is passed down the tree, following the branches based on its feature values, until it reaches a leaf node. The prediction is the value associated with that leaf node.\n",
        "\n",
        "# Q2.What are impurity measures in Decision Trees?\n",
        "Ans:-Impurity measures quantify the homogeneity of a set of data points. In decision trees, they guide the selection of the best feature to split the data at each node.  A lower impurity score indicates a purer node, where most data points belong to the same class. Common impurity measures include:\n",
        "\n",
        "1. Gini Impurity: Measures the probability of incorrectly classifying a randomly chosen element if it were randomly labeled according to the class distribution in the subset. A Gini impurity of 0 indicates a perfectly pure node (all elements belong to the same class).\n",
        "\n",
        "2. Entropy: Measures the uncertainty or randomness in a set of data. An entropy of 0 indicates a perfectly pure node. Entropy is calculated using the formula:  - Σ (p_i * log2(p_i)), where p_i is the probability of an element belonging to class i.\n",
        "\n",
        "3. Classification Error:  The simplest impurity measure, representing the fraction of misclassified elements in a node.  Less frequently used because it is less sensitive to changes in class probabilities compared to Gini impurity and entropy.\n",
        "\n",
        "# Q3.What is the mathematical formula for Gini Impurity\t?\n",
        "Ans:-The formula for Gini impurity is:\n",
        "\n",
        "# Gini impurity = 1 - Σ(p_i)^2\n",
        "\n",
        "# where:\n",
        "p_i is the probability of an element belonging to class i\n",
        "The summation is over all classes present in the subset.\n",
        "\n",
        "# Q4.What is the mathematical formula for Entropy?\n",
        "Ans:-The formula for entropy is:\n",
        "\n",
        "**H(S) = - Σ (p_i * log₂(p_i))**\n",
        "\n",
        "Where:\n",
        "\n",
        "**H(S)** represents the entropy of a set S.\n",
        "**Σ** denotes the sum over all possible classes or values in the set S.\n",
        "**p_i** is the probability of an element belonging to class i (or having value i).\n",
        "**log₂** represents the base-2 logarithm.\n",
        "\n",
        "\n",
        "This formula measures the uncertainty or randomness in the set S.  A higher entropy value indicates greater uncertainty, while an entropy of 0 signifies a perfectly pure set (where all elements belong to the same class or have the same value).\n",
        "\n",
        "# Q5.What is Information Gain, and how is it used in Decision Trees\t?\n",
        "Ans:-Information Gain in Decision Trees\n",
        "Information gain is a crucial concept in decision tree algorithms. It quantifies the reduction in entropy achieved by partitioning a dataset based on a particular feature.  In simpler terms, it measures how much information we gain about the target variable by knowing the value of a specific feature.\n",
        "\n",
        "# Calculation:\n",
        "\n",
        "Information Gain (IG) = Entropy(parent) - [Weighted Average] * Entropy(children)\n",
        "\n",
        "# Where:\n",
        "\n",
        "* Entropy(parent): The entropy of the target variable in the original dataset (before the split).\n",
        "* Entropy(children): The entropy of the target variable in each subset created by the split.\n",
        "* Weighted Average:  The average of the entropies of the children, weighted by the proportion of instances in each child node.\n",
        "\n",
        "# Usage in Decision Trees:\n",
        "\n",
        "1. Feature Selection:  At each node of the decision tree, the algorithm calculates the information gain for every feature.\n",
        "2. Best Split: The feature with the highest information gain is selected as the splitting criterion for that node. This means that this feature provides the most information about the target variable, leading to the purest subsets possible.\n",
        "3. Recursion:  The process is then repeated recursively for each child node until a stopping criterion is met (e.g., maximum tree depth, minimum samples per leaf).\n",
        "\n",
        "# Q6.What is the difference between Gini Impurity and Entropy?\n",
        "Ans:-Gini Impurity and Entropy are both measures of impurity used in decision trees to determine the best split at each node.\n",
        "They both aim to quantify the homogeneity (or heterogeneity) of a set of data points.  While they achieve a similar goal, their mathematical formulations differ slightly, leading to some practical consequences:\n",
        "\n",
        "# Gini Impurity:\n",
        "* Formula: 1 - Σ(p_i)^2  where p_i is the probability of an element belonging to class i.\n",
        "* Focus:  Penalizes the presence of multiple classes in a node more heavily than entropy.  It gives more weight to splits that result in nodes where a single class dominates.\n",
        "* Computationally simpler: It involves squares and sums, making it faster to compute.\n",
        "* Less sensitive to small changes in class distribution: A small change in the class probabilities won't significantly affect the Gini impurity.\n",
        "\n",
        "# Entropy:\n",
        "* Formula: - Σ (p_i * log2(p_i))\n",
        "* Focus:  Measures uncertainty or randomness in a set. It emphasizes the randomness in the set.\n",
        "* Computationally more expensive: The logarithm calculation is slightly more complex.\n",
        "* More sensitive to small changes: A small change in probabilities leads to a bigger change in entropy.\n",
        "* Tends to produce slightly more balanced trees (splits are more evenly distributed).\n",
        "\n",
        "# Q7.What is the mathematical explanation behind Decision Trees?\n",
        "Ans:-\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris # Example dataset\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data  # Features\n",
        "y = iris.target # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Initialize a DecisionTreeClassifier (using Gini impurity by default)\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model (example)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "\n",
        "# To use entropy, you can specify it as the criterion:\n",
        "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "clf_entropy = clf_entropy.fit(X_train, y_train)\n",
        "y_pred_entropy = clf_entropy.predict(X_test)\n",
        "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
        "print(f\"Accuracy (Entropy): {accuracy_entropy}\")\n",
        "\n",
        "# Q8.What is Pre-Pruning in Decision Trees?\n",
        "Ans:-Pre-Pruning in Decision Trees\n",
        "Pre-pruning, also known as early stopping, is a technique used to prevent a decision tree from overfitting the training data.  It involves setting constraints or rules during the tree construction process to limit its growth.  Instead of letting the tree grow to its maximum depth and then pruning it back (post-pruning), pre-pruning stops the tree's growth early based on certain criteria.\n",
        "\n",
        "# Common pre-pruning methods:\n",
        "\n",
        "1. Maximum Depth: Limiting the maximum depth of the tree prevents it from becoming too complex.  A shallower tree is less likely to overfit, but might underfit if the depth is set too low.\n",
        "\n",
        "2. Minimum Samples per Split:  Setting a minimum number of samples required in a node to perform a split.  This prevents splits on very small subsets of data, which are more likely to represent noise rather than genuine patterns.\n",
        "\n",
        "3. Minimum Samples per Leaf: Setting a minimum number of samples required in a leaf node. This prevents the creation of leaf nodes with very few samples, making the tree more robust to outliers and noise.\n",
        "\n",
        "4. Minimum Impurity Decrease:  A split is only made if it decreases the impurity measure (e.g., Gini impurity or entropy) by at least a certain threshold.  This prevents unnecessary splits that provide only minimal improvement in purity.\n",
        "\n",
        "5. Maximum Number of Leaf Nodes:  Limits the total number of leaf nodes in the tree, preventing excessive branching.\n",
        "\n",
        "# Q9.What is Post-Pruning in Decision Trees?\n",
        "Ans:-Post-pruning, also known as backward pruning, is a technique used to reduce the complexity of a decision tree after it has been fully grown.  It involves removing subtrees or branches from a fully grown tree to improve its generalization performance and prevent overfitting.  The basic idea is to simplify the tree by replacing entire subtrees with leaf nodes, effectively \"pruning\" away parts of the tree that are not contributing significantly to its predictive accuracy.\n",
        "\n",
        "Here's how post-pruning generally works:\n",
        "\n",
        "1. **Grow a Full Tree:** First, a decision tree is grown to its maximum extent, without any restrictions on its depth or size.  This allows the tree to learn all possible patterns in the training data.\n",
        "\n",
        "2. **Evaluate Subtrees:**  The algorithm then evaluates the performance of each internal node and its corresponding subtree using a validation set (or through cross-validation).  This evaluation determines how much each subtree contributes to the overall accuracy.  Often, a cost-complexity measure is used to quantify the performance of a subtree.\n",
        "\n",
        "3. **Prune Subtrees:**  The algorithm iteratively removes subtrees that do not significantly improve the model's performance on the validation data.  Instead of the removed subtree, a leaf node is created, predicting the majority class in the subtree's training data.\n",
        "\n",
        "4. **Repeat:** The pruning process is repeated until a desired level of accuracy or a stopping criterion is reached.  Stopping criteria could include:\n",
        "    * A maximum number of pruning iterations\n",
        "    * A threshold on the improvement in performance\n",
        "    * A minimum size for the subtrees\n",
        "\n",
        "# Q10.What is the difference between Pre-Pruning and Post-Pruning?\n",
        "Ans:-Pre-pruning and post-pruning are two different strategies for controlling the complexity of decision trees and preventing overfitting.  Here's a comparison:\n",
        "\n",
        "# Pre-Pruning (Early Stopping)\n",
        "\n",
        "* How it works:  Imposes constraints *during* the tree-building process.  The algorithm stops growing the tree before it reaches its maximum size based on predefined criteria (e.g., maximum depth, minimum samples per leaf).\n",
        "# * Advantages:\n",
        "* Computationally less expensive:  Stops the algorithm early, reducing the time and resources needed for training.\n",
        "* Less prone to overfitting:  By limiting the tree's growth, pre-pruning directly addresses overfitting.\n",
        "\n",
        "# * Disadvantages:\n",
        "* May underfit if the stopping criteria are too strict:  The tree might not be complex enough to capture the true underlying patterns in the data, resulting in suboptimal performance.\n",
        "* Difficult to choose optimal parameters: Determining the best stopping criteria (e.g., depth, minimum samples) can be challenging and often requires experimentation or cross-validation.\n",
        "\n",
        "# Post-Pruning (Backward Pruning)\n",
        "\n",
        "* How it works:  The tree is first grown to its full extent, and *then* subtrees are removed or replaced with leaf nodes based on their impact on performance.  This usually involves a validation set or cross-validation to evaluate the performance of pruned subtrees.\n",
        "# * Advantages:\n",
        "* Less likely to underfit: The full tree is first constructed, allowing the algorithm to discover more complex relationships in the data.\n",
        "* More flexible:  Can fine-tune the tree more precisely by removing only the less relevant parts.\n",
        "\n",
        "# * Disadvantages:\n",
        "* Computationally more expensive:  The full tree must be grown first, which can be time-consuming, especially for large datasets.\n",
        "* More complex to implement: Post-pruning requires evaluation of various subtrees and validation sets.\n",
        "\n",
        "# Q11.What is a Decision Tree Regressor?\n",
        "Ans:-\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Sample data (replace with your own data)\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the regressor\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "\n",
        "# Q12.What are the advantages and disadvantages of Decision Trees?\n",
        "Ans:-\n",
        "# Advantages and Disadvantages of Decision Trees\n",
        "# Advantages:\n",
        "\n",
        "1. Easy to Understand and Interpret: Decision trees are visually appealing and easy to understand, even for non-technical users. The rules and decisions are clear and transparent.\n",
        "2. Requires Little Data Preparation: Decision trees handle both numerical and categorical features well, and they often require less data preprocessing than other algorithms.  Missing values can often be handled without imputation.\n",
        "3. Can Handle Both Categorical and Numerical Data: Decision trees are versatile and can be used for both classification and regression tasks with minimal modifications.\n",
        "4. Non-parametric: Decision trees are non-parametric methods, which means they do not assume any underlying distribution for the data.  This makes them robust to outliers and non-linear relationships.\n",
        "5. White Box Model:  The reasoning behind a decision tree's predictions is easily traceable, allowing for insights into feature importance.\n",
        "6. Fast Predictions: Predictions are very fast because they involve traversing a tree structure.\n",
        "\n",
        "# Disadvantages:\n",
        "1. Prone to Overfitting: Decision trees can be very sensitive to noise in the data and may create overly complex trees that don't generalize well to unseen data.\n",
        "2. Instability: Small changes in the data can lead to large changes in the structure of the decision tree.  This instability can lead to different results for slightly different datasets.\n",
        "3. Biased towards Features with Many Categories:  Features with more categories may be unfairly favored by the algorithm, leading to biased trees.\n",
        "4. Can Create Complex Trees:  Decision trees can become very large and complex, making them difficult to interpret and visualize if not pruned effectively.\n",
        "5. Greedy Algorithm:  Decision trees use a greedy approach to build the tree, meaning they make the locally optimal choice at each step, without considering the potential impact on the overall structure.  This might lead to a suboptimal overall tree.\n",
        "\n",
        "# Q13.How does a Decision Tree handle missing values?\n",
        "Ans:-\n",
        "# Handling Missing Values in Decision Trees\n",
        "# Decision trees can handle missing values in a few ways:\n",
        "\n",
        "# 1. Surrogate Splits:\n",
        "- For a feature with missing values, the algorithm looks for other features that are highly correlated with it.\n",
        "- These correlated features are used as \"surrogate splitters\" when encountering missing values in the original feature.  If no good surrogate is found, the instance is typically assigned to the most common class or the majority class in the node.\n",
        "\n",
        "# 2. Imputation (Preprocessing):\n",
        "- Fill in missing values using a strategy like the mean, median, or mode of the non-missing values for a feature.  Alternatively use more sophisticated methods (KNN imputation, etc.).  In many implementations, the user can choose the imputation strategy.\n",
        "- This approach modifies the data before building the tree.\n",
        "\n",
        "# 3. Special Handling During Tree Construction:\n",
        "- Some implementations handle missing values directly during tree construction. They could split the data according to the non-missing values, assign the instances with missing values to the majority class in the subtree, or use a probabilistic approach.\n",
        "\n",
        "\n",
        "# Example using imputation with scikit-learn (as a preprocessing step)\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Example with missing data\n",
        "X = np.array([[1, 2, np.nan], [4, 5, 6], [7, 8, 9], [10, np.nan, 12]])\n",
        "y = np.array([0, 1, 0, 1])\n",
        "\n",
        "# Impute missing values with the mean\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "# Q14. How does a Decision Tree handle categorical features?\n",
        "Ans:- Handling Categorical Features in Decision Trees\n",
        "# Decision trees can handle categorical features directly.  There are several ways they do this:\n",
        "\n",
        "# 1. One-Hot Encoding:\n",
        "- Convert categorical features into numerical representations by creating binary (0 or 1) columns for each category.\n",
        "- This approach avoids imposing an order on the categories.  If you have 'color' feature with 'red', 'green', and 'blue' categories:\n",
        "- 'color_red' = 1, 'color_green' = 0, 'color_blue' = 0 (if the instance is red)\n",
        "- 'color_red' = 0, 'color_green' = 1, 'color_blue' = 0 (if the instance is green)\n",
        "- 'color_red' = 0, 'color_green' = 0, 'color_blue' = 1 (if the instance is blue)\n",
        "- It's commonly used with libraries like scikit-learn.  There is no need to pre-encode categories manually.\n",
        "\n",
        "# 2. Label Encoding (Ordinal Encoding):\n",
        "- Assigns a unique integer to each category.\n",
        "- This approach implies an order among the categories, which may or may not be appropriate depending on the feature.  For example:\n",
        "- 'low' = 0, 'medium' = 1, 'high' = 2\n",
        "- if categories do not have an inherent order, this can mislead the decision tree.\n",
        "- Not recommended for nominal (unordered) categorical features.\n",
        "\n",
        "# 3. Target Encoding (Mean Encoding):\n",
        "- Replaces each category with the average value of the target variable for that category.\n",
        "- Useful when the number of categories is large and the feature is predictive.\n",
        "\n",
        "# 4. Binary Encoding\n",
        "- A way to encode categorical features with fewer bits than one-hot encoding. Each unique category is assigned a unique binary representation.  Suitable when you have many unique categories.\n",
        "\n",
        "\n",
        "# Scikit-learn's DecisionTreeClassifier automatically handles these encodings for you internally.\n",
        "# Example: (using One-hot-like encoding internally)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create Sample Data (with a categorical feature 'color')\n",
        "data = {\n",
        "    'color': ['red', 'green', 'blue', 'red', 'green', 'blue', 'red', 'green'],\n",
        "    'size': [10, 12, 15, 11, 13, 16, 9, 14],\n",
        "    'target': [0, 1, 0, 0, 1, 1, 0, 1],  # Example target variable\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert categorical features into numbers using pandas get_dummies (One-hot like)\n",
        "X = pd.get_dummies(df[['color', 'size']], columns=['color'], drop_first=True) # drop_first removes multicollinearity\n",
        "y = df['target']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Q15. What are some real-world applications of Decision Trees?\n",
        "Ans:-\n",
        "# Real-World Applications of Decision Trees.\n",
        "# 1. Medical Diagnosis:\n",
        "Decision trees can be used to diagnose diseases based on patient symptoms and medical history.  For example, a decision tree could be trained on data from patients with different heart conditions, and then used to predict the likelihood of a patient having a particular condition.\n",
        "\n",
        "# 2. Customer Churn Prediction:\n",
        "Telecom companies use decision trees to predict which customers are likely to switch to a different provider.  This allows them to take proactive steps to retain valuable customers.  Features used in the model could include call minutes, data usage, customer service interactions, etc.\n",
        "\n",
        "# 3. Fraud Detection:\n",
        "Banks and credit card companies employ decision trees to detect fraudulent transactions. The model would learn patterns from historical data and flag transactions that deviate significantly from normal behavior.\n",
        "\n",
        "# 4. Loan Approval:\n",
        "Financial institutions use decision trees to assess loan applications and determine creditworthiness. Features might include income, credit history, employment status, and debt-to-income ratio.\n",
        "\n",
        "# 5. Image Recognition:\n",
        "Decision trees can be used as part of a larger image recognition system.  They might classify an image based on initial features extracted from it, making it faster than complex deep learning methods.\n",
        "\n",
        "# 6. Risk Assessment:\n",
        "Insurance companies use decision trees to evaluate risks and determine insurance premiums.\n",
        "\n",
        "# 7. Customer Segmentation:\n",
        "Businesses use decision trees to segment customers into different groups based on their demographics, purchasing behavior, and other factors.  This helps tailor marketing campaigns and product recommendations.\n",
        "\n",
        "# 8. Recommender Systems:\n",
        "Decision trees can be used to recommend products or services to users based on their preferences and past behavior.  For example, recommending a movie or item based on other users with similar preferences.\n",
        "\n",
        "# 9. Machine Fault Diagnosis:\n",
        "In manufacturing, decision trees are used to diagnose faults in machines based on sensor data.  This allows maintenance to be performed before a major failure occurs.\n",
        "\n",
        "# 10. Credit Risk Scoring:\n",
        "Financial institutions can employ decision trees for more granular credit scoring, leading to more tailored credit terms and offers.\n"
      ],
      "metadata": {
        "id": "AupchewMp75s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practical"
      ],
      "metadata": {
        "id": "lkumSeIHwmV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q16.Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Initialize a DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vaHoFR8wpRY",
        "outputId": "a29edcff-0b3b-418e-d8b5-cc8f05c86057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q17.Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances\n",
        "# Initialize a DecisionTreeClassifier with Gini impurity\n",
        "clf_gini = DecisionTreeClassifier(criterion=\"gini\")\n",
        "\n",
        "# Train the classifier\n",
        "clf_gini = clf_gini.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Feature Importances (Gini):\", clf_gini.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fImKyUAxHka",
        "outputId": "19de04c3-cb5d-430c-d41f-22860d821661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances (Gini): [0.         0.04300928 0.90006666 0.05692405]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q18.Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy\n",
        "\n",
        "# Initialize a DecisionTreeClassifier with entropy as the criterion\n",
        "clf_entropy = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "\n",
        "# Train the classifier\n",
        "clf_entropy = clf_entropy.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_entropy = clf_entropy.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_entropy = accuracy_score(y_test, y_pred_entropy)\n",
        "print(f\"Accuracy (Entropy): {accuracy_entropy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0fR5u9WxaqA",
        "outputId": "1dac97ae-a5f4-4446-bc75-5e455725204c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Entropy): 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q19.Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree Regressor model\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print the Mean Squared Error\n",
        "print(f'Mean Squared Error: {mse:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgh0tIF_xpHk",
        "outputId": "5bc6756e-9234-42af-f270-6e3224a3c25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q20.Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz.\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Export as DOT file\n",
        "dot_data = export_graphviz(\n",
        "    clf,\n",
        "    out_file=None,\n",
        "    feature_names=iris.feature_names,\n",
        "    class_names=iris.target_names,\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    special_characters=True\n",
        ")\n",
        "\n",
        "# Visualize the tree using Graphviz\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"iris_tree\", format='png', cleanup=False)  # Saves the tree as iris_tree.png\n",
        "graph.view(\"iris_tree\")  # Opens the image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XfvQ74cmyNDv",
        "outputId": "dffb6ba9-0cc8-4928-abb7-553a739dc973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'iris_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q21.Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Train a fully grown Decision Tree Classifier\n",
        "clf_full = DecisionTreeClassifier()\n",
        "clf_full.fit(X_train, y_train)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "print(f\"Accuracy (Fully Grown Tree): {accuracy_full}\")\n",
        "\n",
        "# Train a Decision Tree Classifier with a maximum depth of 3\n",
        "clf_pruned = DecisionTreeClassifier(max_depth=3)\n",
        "clf_pruned.fit(X_train, y_train)\n",
        "y_pred_pruned = clf_pruned.predict(X_test)\n",
        "accuracy_pruned = accuracy_score(y_test, y_pred_pruned)\n",
        "print(f\"Accuracy (Pruned Tree - max_depth=3): {accuracy_pruned}\")"
      ],
      "metadata": {
        "id": "I8CZbyabytCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6beea7c0-0453-4df1-c346-134b4254ee47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Fully Grown Tree): 0.9777777777777777\n",
            "Accuracy (Pruned Tree - max_depth=3): 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q22.Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree.\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Train a Decision Tree Classifier with min_samples_split=5\n",
        "clf_min_samples = DecisionTreeClassifier(min_samples_split=5)\n",
        "clf_min_samples.fit(X_train, y_train)\n",
        "y_pred_min_samples = clf_min_samples.predict(X_test)\n",
        "accuracy_min_samples = accuracy_score(y_test, y_pred_min_samples)\n",
        "print(f\"Accuracy (min_samples_split=5): {accuracy_min_samples}\")\n",
        "\n",
        "# Train a default Decision Tree Classifier\n",
        "clf_default = DecisionTreeClassifier()\n",
        "clf_default.fit(X_train, y_train)\n",
        "y_pred_default = clf_default.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "print(f\"Accuracy (Default): {accuracy_default}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3NDH2zVzNOc",
        "outputId": "c9abe596-c5bd-4a0c-c657-d93077076820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (min_samples_split=5): 0.9777777777777777\n",
            "Accuracy (Default): 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q23.Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Train a Decision Tree Classifier without scaling\n",
        "clf_no_scaling = DecisionTreeClassifier()\n",
        "clf_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = clf_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "print(f\"Accuracy (No Scaling): {accuracy_no_scaling}\")\n",
        "\n",
        "# Apply feature scaling (StandardScaler)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Decision Tree Classifier with scaled data\n",
        "clf_scaled = DecisionTreeClassifier()\n",
        "clf_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = clf_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy (With Scaling): {accuracy_scaled}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYZUVzl1zfHh",
        "outputId": "107e0436-316b-4f93-a554-85a168e5066d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (No Scaling): 0.9777777777777777\n",
            "Accuracy (With Scaling): 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q24.Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification.\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Initialize a DecisionTreeClassifier\n",
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "# Use OneVsRestClassifier with the DecisionTreeClassifier\n",
        "ovr_classifier = OneVsRestClassifier(dtc)\n",
        "\n",
        "# Train the OvR classifier\n",
        "ovr_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = ovr_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy (One-vs-Rest): {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA-14L_7zxbH",
        "outputId": "7b03235f-7548-4ef9-e726-c2380fec08ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (One-vs-Rest): 0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores\n",
        "# Train the classifier\n",
        "clf = clf.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Feature Importances:\", clf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XztgNC4_0Bj5",
        "outputId": "066bf8a1-64d9-496b-be1c-cb94a42dc7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances: [0.         0.02150464 0.39766951 0.58082584]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q26.Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree.\n",
        "import pandas as pd\n",
        "# Load the California housing dataset\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "data = fetch_california_housing()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Decision Tree Regressor model with max_depth=5\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "model_depth5 = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "model_depth5.fit(X_train, y_train)\n",
        "y_pred_depth5 = model_depth5.predict(X_test)\n",
        "\n",
        "# Create a Decision Tree Regressor model with no depth restriction\n",
        "model_unrestricted = DecisionTreeRegressor(random_state=42)\n",
        "model_unrestricted.fit(X_train, y_train)\n",
        "y_pred_unrestricted = model_unrestricted.predict(X_test)\n",
        "\n",
        "# Evaluate both models using Mean Squared Error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse_depth5 = mean_squared_error(y_test, y_pred_depth5)\n",
        "mse_unrestricted = mean_squared_error(y_test, y_pred_unrestricted)\n",
        "\n",
        "print(f'Mean Squared Error (max_depth=5): {mse_depth5:.2f}')\n",
        "print(f'Mean Squared Error (unrestricted): {mse_unrestricted:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6OKEaHE0QYX",
        "outputId": "eb6eb87a-3218-4957-c79f-ac7f65fe6e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (max_depth=5): 0.52\n",
            "Mean Squared Error (unrestricted): 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q27.Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a decision tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "\n",
        "# Train decision trees with different CCP alpha values\n",
        "clfs = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
        "    clf.fit(X_train, y_train)\n",
        "    clfs.append(clf)\n",
        "\n",
        "# Evaluate accuracy for each tree\n",
        "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
        "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
        "\n",
        "# Plot the accuracy vs. CCP alpha\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_xlabel(\"alpha\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
        "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\", drawstyle=\"steps-post\")\n",
        "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\", drawstyle=\"steps-post\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "hY1sw3w_0iEG",
        "outputId": "da575ca6-9468-45d9-dfb9-5f8d4a35edb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q28.Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have already trained a Decision Tree Classifier (clf) and made predictions (y_pred)\n",
        "# ... your existing code to train the model ...\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")"
      ],
      "metadata": {
        "id": "KSlt1sXZ1lob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862761da-963b-4ae6-a871-aa2dd0a4216a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.22875816993464054\n",
            "Recall: 0.2222222222222222\n",
            "F1-Score: 0.22361904761904763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q29.Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming you have already trained a Decision Tree Classifier (clf) and made predictions (y_pred)\n",
        "# ... your existing code to train the model ...\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the confusion matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "l9zeChdc5ot0",
        "outputId": "1797a08a-7c6a-4b5f-ba6d-103ad6a1d5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAncAAAIjCAYAAABh1T2DAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATX5JREFUeJzt3Xd8FNX+//H3BpJNSKcnlFACoQiEYoGIgDRREOUqIqgUQa+IKEjLVSABEbBQRC9dmoAiTQWRKlIVREIT6Z0gXEIPJCGZ3x982Z9LAiSQMMvs6+ljHw/27Mw5n907Fz9+zpkzNsMwDAEAAMASPMwOAAAAANmH5A4AAMBCSO4AAAAshOQOAADAQkjuAAAALITkDgAAwEJI7gAAACyE5A4AAMBCSO4AAAAshOQOwC3t2bNHjRo1UmBgoGw2m+bPn5+t/R88eFA2m02TJ0/O1n7vZ3Xr1lXdunXNDgPAfYrkDrgP7Nu3T6+//rpKlSolb29vBQQEKCoqSiNHjtTly5dzdOy2bdtq27ZtGjRokKZNm6YaNWrk6Hj3Urt27WSz2RQQEJDh77hnzx7ZbDbZbDZ98sknWe7/+PHjiomJUVxcXDZECwCZk9vsAADc2sKFC/X888/LbrfrlVde0QMPPKDk5GStWbNGPXv21I4dOzRu3LgcGfvy5ctav3693nvvPXXp0iVHxggLC9Ply5fl6emZI/3fTu7cuZWYmKgffvhBLVu2dPps+vTp8vb21pUrV+6o7+PHjys2NlYlSpRQZGRkps9bsmTJHY0HABLJHeDSDhw4oFatWiksLEwrVqxQSEiI47M333xTe/fu1cKFC3Ns/FOnTkmSgoKCcmwMm80mb2/vHOv/dux2u6KiojRz5sx0yd2MGTP01FNPac6cOfcklsTEROXJk0deXl73ZDwA1sS0LODCPvroI128eFETJ050SuyuCw8P19tvv+14f/XqVQ0cOFClS5eW3W5XiRIl9J///EdJSUlO55UoUUJNmzbVmjVr9NBDD8nb21ulSpXS1KlTHcfExMQoLCxMktSzZ0/ZbDaVKFFC0rXpzOt//qeYmBjZbDantqVLl+rRRx9VUFCQ/Pz8FBERof/85z+Oz2+25m7FihWqXbu2fH19FRQUpObNm2vnzp0Zjrd37161a9dOQUFBCgwMVPv27ZWYmHjzH/YGrVu31qJFi3T27FlH28aNG7Vnzx61bt063fEJCQnq0aOHKlWqJD8/PwUEBKhJkybasmWL45iVK1fqwQcflCS1b9/eMb17/XvWrVtXDzzwgDZt2qTHHntMefLkcfwuN665a9u2rby9vdN9/8aNGys4OFjHjx/P9HcFYH0kd4AL++GHH1SqVCnVqlUrU8d37NhR/fr1U7Vq1TR8+HDVqVNHgwcPVqtWrdIdu3fvXj333HNq2LChPv30UwUHB6tdu3basWOHJKlFixYaPny4JOnFF1/UtGnTNGLEiCzFv2PHDjVt2lRJSUkaMGCAPv30Uz399NNau3btLc9btmyZGjdurJMnTyomJkbdu3fXunXrFBUVpYMHD6Y7vmXLlrpw4YIGDx6sli1bavLkyYqNjc10nC1atJDNZtPcuXMdbTNmzFC5cuVUrVq1dMfv379f8+fPV9OmTTVs2DD17NlT27ZtU506dRyJVvny5TVgwABJ0muvvaZp06Zp2rRpeuyxxxz9nD59Wk2aNFFkZKRGjBihevXqZRjfyJEjVaBAAbVt21apqamSpLFjx2rJkiUaNWqUQkNDM/1dAbgBA4BLOnfunCHJaN68eaaOj4uLMyQZHTt2dGrv0aOHIclYsWKFoy0sLMyQZKxatcrRdvLkScNutxvvvvuuo+3AgQOGJOPjjz926rNt27ZGWFhYuhj69+9v/POvleHDhxuSjFOnTt007utjTJo0ydEWGRlpFCxY0Dh9+rSjbcuWLYaHh4fxyiuvpBuvQ4cOTn0+++yzRr58+W465j+/h6+vr2EYhvHcc88Z9evXNwzDMFJTU43ChQsbsbGxGf4GV65cMVJTU9N9D7vdbgwYMMDRtnHjxnTf7bo6deoYkowxY8Zk+FmdOnWc2hYvXmxIMj744ANj//79hp+fn/HMM8/c9jsCcD9U7gAXdf78eUmSv79/po7/8ccfJUndu3d3an/33XclKd3avAoVKqh27dqO9wUKFFBERIT2799/xzHf6Ppave+++05paWmZOic+Pl5xcXFq166d8ubN62ivXLmyGjZs6Pie//Tvf//b6X3t2rV1+vRpx2+YGa1bt9bKlSt14sQJrVixQidOnMhwSla6tk7Pw+PaX5+pqak6ffq0Y8r5jz/+yPSYdrtd7du3z9SxjRo10uuvv64BAwaoRYsW8vb21tixYzM9FgD3QXIHuKiAgABJ0oULFzJ1/KFDh+Th4aHw8HCn9sKFCysoKEiHDh1yai9evHi6PoKDg3XmzJk7jDi9F154QVFRUerYsaMKFSqkVq1aadasWbdM9K7HGRERke6z8uXL63//+58uXbrk1H7jdwkODpakLH2XJ598Uv7+/vrmm280ffp0Pfjgg+l+y+vS0tI0fPhwlSlTRna7Xfnz51eBAgW0detWnTt3LtNjFilSJEs3T3zyySfKmzev4uLi9Nlnn6lgwYKZPheA+yC5A1xUQECAQkNDtX379iydd+MNDTeTK1euDNsNw7jjMa6vB7vOx8dHq1at0rJly/Tyyy9r69ateuGFF9SwYcN0x96Nu/ku19ntdrVo0UJTpkzRvHnzblq1k6QPP/xQ3bt312OPPaavvvpKixcv1tKlS1WxYsVMVyila79PVmzevFknT56UJG3bti1L5wJwHyR3gAtr2rSp9u3bp/Xr19/22LCwMKWlpWnPnj1O7X///bfOnj3ruPM1OwQHBzvdWXrdjdVBSfLw8FD9+vU1bNgw/fnnnxo0aJBWrFihn3/+OcO+r8e5a9eudJ/99ddfyp8/v3x9fe/uC9xE69attXnzZl24cCHDm1Cumz17turVq6eJEyeqVatWatSokRo0aJDuN8lsop0Zly5dUvv27VWhQgW99tpr+uijj7Rx48Zs6x+AdZDcAS6sV69e8vX1VceOHfX333+n+3zfvn0aOXKkpGvTipLS3dE6bNgwSdJTTz2VbXGVLl1a586d09atWx1t8fHxmjdvntNxCQkJ6c69vpnvjduzXBcSEqLIyEhNmTLFKVnavn27lixZ4vieOaFevXoaOHCgPv/8cxUuXPimx+XKlStdVfDbb7/VsWPHnNquJ6EZJcJZ1bt3bx0+fFhTpkzRsGHDVKJECbVt2/amvyMA98UmxoALK126tGbMmKEXXnhB5cuXd3pCxbp16/Ttt9+qXbt2kqQqVaqobdu2GjdunM6ePas6depow4YNmjJlip555pmbbrNxJ1q1aqXevXvr2WefVdeuXZWYmKjRo0erbNmyTjcUDBgwQKtWrdJTTz2lsLAwnTx5Uv/9739VtGhRPfroozft/+OPP1aTJk1Us2ZNvfrqq7p8+bJGjRqlwMBAxcTEZNv3uJGHh4fef//92x7XtGlTDRgwQO3bt1etWrW0bds2TZ8+XaVKlXI6rnTp0goKCtKYMWPk7+8vX19fPfzwwypZsmSW4lqxYoX++9//qn///o6tWSZNmqS6deuqb9+++uijj7LUHwCLM/luXQCZsHv3bqNTp05GiRIlDC8vL8Pf39+IiooyRo0aZVy5csVxXEpKihEbG2uULFnS8PT0NIoVK2ZER0c7HWMY17ZCeeqpp9KNc+MWHDfbCsUwDGPJkiXGAw88YHh5eRkRERHGV199lW4rlOXLlxvNmzc3QkNDDS8vLyM0NNR48cUXjd27d6cb48btQpYtW2ZERUUZPj4+RkBAgNGsWTPjzz//dDrm+ng3brUyadIkQ5Jx4MCBm/6mhuG8FcrN3GwrlHfffdcICQkxfHx8jKioKGP9+vUZbmHy3XffGRUqVDBy587t9D3r1KljVKxYMcMx/9nP+fPnjbCwMKNatWpGSkqK03HdunUzPDw8jPXr19/yOwBwLzbDyMKKYwAAALg01twBAABYCMkdAACAhZDcAQAAWAjJHQAAgAu5cOGC3nnnHYWFhcnHx0e1atXK0r6WJHcAAAAupGPHjlq6dKmmTZumbdu2OTZKv3EvzZvhblkAAAAXcfnyZfn7++u7775z2ny+evXqatKkiT744IPb9sEmxgAAADkoKSkp3dNk7Ha77HZ7umOvXr2q1NRUeXt7O7X7+PhozZo1mRrPkpW7nfGXzA4BSKfak73NDgFw0qHfm2aHADj54tnypo3tU7VLjvXdu3l+xcbGOrX179//pk/cqVWrlry8vDRjxgwVKlRIM2fOVNu2bRUeHp7hc7dvxJo7AACAHBQdHa1z5845vaKjo296/LRp02QYhooUKSK73a7PPvtML774ojw8Mpe2MS0LAABgy7l6182mYG+mdOnS+uWXX3Tp0iWdP39eISEheuGFF9I9v/pmqNwBAADYbDn3ukO+vr4KCQnRmTNntHjxYjVv3jxT51G5AwAAcCGLFy+WYRiKiIjQ3r171bNnT5UrV07t27fP1PkkdwAAADk4LZtV19fkHT16VHnz5tW//vUvDRo0SJ6enpk6n+QOAADAhbRs2VItW7a84/NJ7gAAAO5ibZyrcZ0aJAAAAO4alTsAAAAXWnN3t6zzTQAAAEDlDgAAwEpr7kjuAAAAmJYFAACAK6JyBwAAYKFpWSp3AAAAFkLlDgAAgDV3AAAAcEVU7gAAAFhzBwAAAFdE5Q4AAMBCa+5I7gAAAJiWBQAAgCuicgcAAGChaVnrfBMAAABQuQMAAKByBwAAAJdE5Q4AAMCDu2UBAADggqjcAQAAWGjNHckdAAAAmxgDAADAFVG5AwAAsNC0rHW+CQAAAKjcAQAAsOYOAAAALonKHQAAAGvuAAAA4Iqo3AEAAFhozR3JHQAAANOyAAAAcEVU7gAAACw0LUvlDgAAwEKo3AEAALDmDgAAAK6Iyh0AAABr7gAAAOCKqNwBAABYaM0dyR0AAICFkjvrfBMAAABQuQMAAOCGCgAAALgkKncAAACsuQMAAIAronIHAADAmjsAAAC4Iip3AAAAFlpz51LJ3ZUrV5ScnOzUFhAQYFI0AADAbTAtm30SExPVpUsXFSxYUL6+vgoODnZ6AQAAIPNMT+569uypFStWaPTo0bLb7ZowYYJiY2MVGhqqqVOnmh0eAABwAzabLcde95rp07I//PCDpk6dqrp166p9+/aqXbu2wsPDFRYWpunTp6tNmzZmhwgAAHDfML1yl5CQoFKlSkm6tr4uISFBkvToo49q1apVZoYGAADchJUqd6Ynd6VKldKBAwckSeXKldOsWbMkXavoBQUFmRgZAADA/cf05K59+/basmWLJKlPnz764osv5O3trW7duqlnz54mRwcAANyCLQdf95jpa+66devm+HODBg30119/adOmTQoPD1flypVNjAwAAOD+Y3pyd6OwsDAFBgYyJQsAAO4ZM9bG5RTTp2WHDh2qb775xvG+ZcuWypcvn4oUKeKYrgUAAMhJ3FCRjcaMGaNixYpJkpYuXaqlS5dq0aJFatKkCWvuAAAAssj0adkTJ044krsFCxaoZcuWatSokUqUKKGHH37Y5OgAAIA7YFo2GwUHB+vIkSOSpJ9++kkNGjSQJBmGodTUVDNDAwAAuO+YXrlr0aKFWrdurTJlyuj06dNq0qSJJGnz5s0KDw83OToAAOAOrFS5Mz25Gz58uEqUKKEjR47oo48+kp+fnyQpPj5enTt3Njk6zJk+SdPGj1LTf72ojm+xBhLm8ctjV//OTfX041VUINhPW3YdVY+PZmvTn4fNDg1uKtA7t56pWFAVCvvKK5eHTl1M1ld/xOvw2StmhwY3Z3py5+npqR49eqRr/+f+dzDHnr92aPEPc1SidBmzQwE0ul9rVQgPVYf3pyj+1Dm9+ORDWjjmLVX71wc6fuqc2eHBzfh4eujdx8K0+3+J+u+6I7qYlKoCfl5KTGE50X3LOoU789fcSdK+ffv01ltvqUGDBmrQoIG6du2q/fv3mx2WW7ucmKjhH7ynN3v0la9fgNnhwM152z31TP1IvTdivtb+sU/7j/xPg8b+qH1HTqnT87XNDg9uqFHZfDpz+aq++iNeh85c0enEFP118pL+dynF7NBwn0tNTVXfvn1VsmRJ+fj4qHTp0ho4cKAMw8h0H6ZX7hYvXqynn35akZGRioqKkiStXbtWFSpU0A8//KCGDRuaHKF7GjdyiKo/8qiq1HhYs6ZNMDscuLncuTyUO3cuXUl2/hfnlaQU1apa2qSo4M4qFfbXzpMX9epDRVQmfx6dvXxVqw6c0bqDZ80ODXfIVdbcDR06VKNHj9aUKVNUsWJF/f7772rfvr0CAwPVtWvXTPVhenLXp08fdevWTUOGDEnX3rt3b5I7E6xevlj7dv+lT8ZMMzsUQJJ0MTFJv27Zr+hOTbTrwN/6+/R5tXyihh6uXFL7jpwyOzy4ofy+nqpdMlgr9iZo8a7/KSzYR89XLqTUNEO/HWaZAO7cunXr1Lx5cz311FOSpBIlSmjmzJnasGFDpvswfVp2586devXVV9O1d+jQQX/++edtz09KStL58+edXslJSTkRqls4dfKEJnz+sbq//4G87HazwwEcOrw/VTabtH/JIJ37bYTefLGOZv30u9LSMj9VAWQXm82mI2ev6Ps/T+nouSStPXhW6w6e1aMlg8wODXcoJ59QkVGuknSTXKVWrVpavny5du/eLUnasmWL1qxZ49hNJDNMT+4KFCiguLi4dO1xcXEqWLDgbc8fPHiwAgMDnV7jRn2SA5G6h327durcmQR179RGLR5/UC0ef1A7tmzSwrlfq8XjD7L3IExz4Oj/1KjjSOWr2V1lmvRV7Zc/kWfuXDpw7H9mhwY3dP7KVcVfSHZqO3EhSXl9PE2KCHcrJ5O7jHKVwYMHZxhHnz591KpVK5UrV06enp6qWrWq3nnnHbVp0ybT38X0adlOnTrptdde0/79+1WrVi1J19bcDR06VN27d7/t+dHR0emOO5BwNUdidQdVqj+kkV/OcmobNTRGRYqXUIsX2ylXrlwmRQZck3glWYlXkhXk76MGtcrrvRHfmR0S3NC+04kq5Ofl1FbQz0sJidxQgfQyylXsN5kdmzVrlqZPn64ZM2aoYsWKiouL0zvvvKPQ0FC1bds2U+OZntz17dtX/v7++vTTTxUdHS1JCg0NVUxMTKYWDtrt9nQ/kNelSzkSqzvwyeOrsFLOm0fbvX3kHxCYrh24lxrULC+bTdp98KRKFyugD7s9o90H/tbU79ebHRrc0Iq9CepRp4Qal82nP46dV1iwj6JKBGvm5nizQ8MdyskbKjLKVW6mZ8+ejuqdJFWqVEmHDh3S4MGD75/kzmazqVu3burWrZsuXLggSfL39zc5KgCuJtDPWwPeelpFCgUp4Vyivlsep/5f/KCrV9PMDg1u6PDZKxr321E9XaGAmpTLr9OJKZq97W9tPHre7NBwn0tMTJSHh/OquVy5ciktLfN/15me3D3++OOaO3eugoKCnJK68+fP65lnntGKFStMjA6SNGjkeLNDADRn6WbNWbrZ7DAAh+0nLmr7iYtmh4Hs4ho7oahZs2YaNGiQihcvrooVK2rz5s0aNmyYOnTokOk+TE/uVq5cqeTk5HTtV65c0erVq02ICAAAwByjRo1S37591blzZ508eVKhoaF6/fXX1a9fv0z3YVpyt3XrVsef//zzT504ccLxPjU1VT/99JOKFCliRmgAAMDNuMomxv7+/hoxYoRGjBhxx32YltxFRkY6bhF+/PHH033u4+OjUaNGmRAZAADA/cu05O7AgQMyDEOlSpXShg0bVKBAAcdnXl5eKliwINtuAACAe8JVKnfZwbTkLiwsTJKydPcHAABATrBScmf6Eyokadq0aYqKilJoaKgOHTokSRo+fLi++47NSQEAALLC9ORu9OjR6t69u5588kmdPXvW8Xir4ODgu1pMCAAAkGm2HHzdY6Ynd6NGjdL48eP13nvvOa2xq1GjhrZt22ZiZAAAAPcf0/e5O3DggKpWrZqu3W636xKPEQMAAPcAa+6yUcmSJRUXF5eu/aefflL58uXvfUAAAAD3MdMrd927d9ebb76pK1euyDAMbdiwQTNnztTgwYM1YcIEs8MDAABuwEqVO9OTu44dO8rHx0fvv/++EhMT1bp1axUpUkQjR45Uq1atzA4PAADgvmJ6cnf58mU9++yzatOmjRITE7V9+3atXbtWRYsWNTs0AADgJqxUuTN9zV3z5s01depUSVJycrKefvppDRs2TM8884xGjx5tcnQAAMAdXH8kak687jXTk7s//vhDtWvXliTNnj1bhQoV0qFDhzR16lR99tlnJkcHAABwfzF9WjYxMVH+/v6SpCVLlqhFixby8PDQI4884nhaBQAAQI6yzqys+ZW78PBwzZ8/X0eOHNHixYvVqFEjSdLJkycVEBBgcnQAAAD3F9OTu379+qlHjx4qUaKEHn74YdWsWVPStSpeRpsbAwAAZDcrrbkzfVr2ueee06OPPqr4+HhVqVLF0V6/fn09++yzJkYGAABw/zE9uZOkwoULq3Dhwk5tDz30kEnRAAAAd8NWKAAAAHBJLlG5AwAAMJOVKnckdwAAANbJ7ZiWBQAAsBIqdwAAwO1ZaVqWyh0AAICFULkDAABuj8odAAAAXBKVOwAA4Pao3AEAAMAlUbkDAABuz0qVO5I7AAAA6+R2TMsCAABYCZU7AADg9qw0LUvlDgAAwEKo3AEAALdH5Q4AAAAuicodAABwexYq3FG5AwAAsBIqdwAAwO1Zac0dyR0AAHB7FsrtmJYFAACwEip3AADA7VlpWpbKHQAAgIVQuQMAAG7PQoU7KncAAABWQuUOAAC4PQ8P65TuqNwBAABYCJU7AADg9qy05o7kDgAAuD22QgEAAIBLonIHAADcnoUKd1TuAAAArITKHQAAcHusuQMAAIBLonIHAADcHpU7AAAAuCQqdwAAwO1ZqHBHcgcAAMC0LAAAAFwSlTsAAOD2LFS4o3IHAABgJVTuAACA22PNHQAAAFwSlTsAAOD2LFS4o3IHAABgJVTuAACA22PNHQAAAFwSyR0AAHB7NlvOvbKiRIkSstls6V5vvvlmpvtgWhYAALg9V5mW3bhxo1JTUx3vt2/froYNG+r555/PdB8kdwAAAC6iQIECTu+HDBmi0qVLq06dOpnug+QOAAC4vZws3CUlJSkpKcmpzW63y2633/K85ORkffXVV+revXuWKouWTO7aT/nd7BCAdM5s/NzsEAAAJhg8eLBiY2Od2vr376+YmJhbnjd//nydPXtW7dq1y9J4lkzuAAAAsiIn19xFR0ere/fuTm23q9pJ0sSJE9WkSROFhoZmaTySOwAAgByUmSnYGx06dEjLli3T3LlzszweyR0AAHB7LnKzrMOkSZNUsGBBPfXUU1k+l33uAAAAXEhaWpomTZqktm3bKnfurNfhqNwBAAC35yr73EnSsmXLdPjwYXXo0OGOzie5AwAAbs+Fcjs1atRIhmHc8flMywIAAFgIlTsAAOD2XGla9m5RuQMAALAQKncAAMDtUbkDAACAS6JyBwAA3J6FCndU7gAAAKyEyh0AAHB7VlpzR3IHAADcnoVyO6ZlAQAArITKHQAAcHtWmpalcgcAAGAhVO4AAIDbs1DhjsodAACAlVC5AwAAbs/DQqU7KncAAAAWQuUOAAC4PQsV7kjuAAAA2AoFAAAALonKHQAAcHse1incUbkDAACwEip3AADA7bHmDgAAAC6Jyh0AAHB7FircUbkDAACwEip3AADA7dlkndIdyR0AAHB7bIUCAAAAl0TlDgAAuD22QgEAAIBLonIHAADcnoUKd1TuAAAArITKHQAAcHseFirdUbkDAACwECp3AADA7VmocEdyBwAAwFYoAAAAcElU7gAAgNuzUOHO3MpdSkqK6tevrz179pgZBgAAgGWYWrnz9PTU1q1bzQwBAACArVCy00svvaSJEyeaHQYAAIAlmL7m7urVq/ryyy+1bNkyVa9eXb6+vk6fDxs2zKTIAACAu7BO3c4Fkrvt27erWrVqkqTdu3c7fWal25IBAADuBdOTu59//tnsEAAAgJuzUkHJ9OTun44ePSpJKlq0qMmRAAAAd+JhndzO/Bsq0tLSNGDAAAUGBiosLExhYWEKCgrSwIEDlZaWZnZ4AAAA9xXTK3fvvfeeJk6cqCFDhigqKkqStGbNGsXExOjKlSsaNGiQyRECAACrY1o2G02ZMkUTJkzQ008/7WirXLmyihQpos6dO5PcAQAAZIHpyV1CQoLKlSuXrr1cuXJKSEgwISIAAOBuLFS4M3/NXZUqVfT555+na//8889VpUoVEyICAAC4f5leufvoo4/01FNPadmyZapZs6Ykaf369Tpy5Ih+/PFHk6MDAADuwEpr7kyv3NWpU0e7d+/Ws88+q7Nnz+rs2bNq0aKFdu3apdq1a5sdHgAAwH3F9MqdJIWGhnLjBAAAMI2V9rkzJbnbunVrpo+tXLlyDkYCAABgrWlZU5K7yMhI2Ww2GYZxy+NsNptSU1PvUVQAAAD3P1OSuwMHDpgxLAAAQIasU7czKbkLCwszY1gAAADLu6O7ZVevXq2XXnpJNWvW1LFjxyRJ06ZN05o1a+4oiH379umtt95SgwYN1KBBA3Xt2lX79u27o74AAACyysNmy7HXPf8uWT1hzpw5aty4sXx8fLR582YlJSVJks6dO6cPP/wwywEsXrxYFSpU0IYNG1S5cmVVrlxZv/32mypWrKilS5dmuT8AAAB3luVp2Q8++EBjxozRK6+8oq+//trRHhUVpQ8++CDLAfTp00fdunXTkCFD0rX37t1bDRs2zHKfAAAAWWGhm2WzXrnbtWuXHnvssXTtgYGBOnv2bJYD2Llzp1599dV07R06dNCff/6Z5f4AAADcWZaTu8KFC2vv3r3p2tesWaNSpUplOYACBQooLi4uXXtcXJwKFiyY5f4AAACyymaz5djrXsvytGynTp309ttv68svv5TNZtPx48e1fv169ejRQ3379s1yAJ06ddJrr72m/fv3q1atWpKktWvXaujQoerevXuW+wMAAHBnWU7u+vTpo7S0NNWvX1+JiYl67LHHZLfb1aNHD7311ltZDqBv377y9/fXp59+qujoaEnXHkcWExOjrl27Zrk/AACArLLSmjubcbvHRNxEcnKy9u7dq4sXL6pChQry8/O762AuXLggSfL397+rfh4Z8stdx+LO5r3xsEICvdO1z950TJ8sTT8lj8xZ2aOO2SHct2Z9PUOzvpmp4/+39VLp8DJ6/Y3OerQ2vynMwTWZM7xNfOL9G3Nybp3/6H9VyLG+M3LHP6OXl5cqVLj7YA8cOKCrV6+qTJkyTkndnj175OnpqRIlStz1GMia9pP/kMc/VmOWzu+rUS9W0Ypdp8wLCm6tYKHCertbDxUPC5NhGPrhu/l6u8ub+mbOPIWHlzE7PLghrkm4siwnd/Xq1bvl4sAVK1Zkqb927dqpQ4cOKlPG+f8Mv/32myZMmKCVK1dmNUTcpbOXU5zev/JIPh05c1l/HD5nUkRwd3XrPe70/q23u2nW1zO1dUsc/yKFKbgmrceVpmWPHTum3r17a9GiRUpMTFR4eLgmTZqkGjVqZOr8LCd3kZGRTu9TUlIUFxen7du3q23btlntTps3b1ZUVFS69kceeURdunTJcn/IXrk9bHqiYiHN3HjU7FAASVJqaqqWLP5Jly8nqkqVqmaHA3BNIludOXNGUVFRqlevnhYtWqQCBQpoz549Cg4OznQfWU7uhg8fnmF7TEyMLl68mNXuZLPZHGvt/uncuXNKTU3Ncn/IXnXK5pefd24t3HbC7FDg5vbs3qWXW7dScnKS8uTJo+GffaHS4eFmhwU3xjVpLWZsWZKRoUOHqlixYpo0aZKjrWTJklnq445vqLjR3r179dBDDykhISFL5zVr1kw+Pj6aOXOmcuXKJenafwW98MILunTpkhYtWnTL85OSkhyPQLuuwWe/ySO3V9a+ADI0omUlXU0z1GP2drNDue9xQ8XdSUlOVnx8vC5evKClSxZr3pxvNXHyV/zLFKbhmsx+Zt5Q8ea8nTnW97AnS6XLVex2u+x2e7pjK1SooMaNG+vo0aP65ZdfVKRIEXXu3FmdOnXK9HhZ3sT4ZtavXy9v7/R3WN7O0KFDtWLFCkVERKh9+/Zq3769IiIitGrVKn388ce3PX/w4MEKDAx0eh1fOf1OvgJuUDjArgdLBOu7LfFmhwLI08tLxcPCVKHiA3q727sqG1FO07+aanZYcGNck9bikYOvjHKVwYMHZxjH/v37NXr0aJUpU0aLFy/WG2+8oa5du2rKlCmZ/i5ZzpFbtGjh9N4wDMXHx+v333+/o02MK1SooK1bt+rzzz/Xli1b5OPjo1deeUVdunRR3rx5b3t+dHR0us2OG3z2W5bjQHpNKxfWmcRkrdt72uxQgHTS0tKUkpxsdhiAA9ckbiajXCWjqp107TqqUaOGPvzwQ0lS1apVtX37do0ZMybT9zZkObkLDAx0eu/h4aGIiAgNGDBAjRo1ymp3kq5tWnz9S2RVRmVNpmTvnk3SU5UK68dtfys1WybugTs3cvinerT2YyocEqLES5f048IF+n3jBo0eN9Hs0OCmuCatJyfX3N1sCjYjISEh6baaK1++vObMmZPp8bKU3KWmpqp9+/aqVKlSlu7auNHWrVv1wAMPyMPDQ1u3br3lsZUrV77jcXDnHiwRrJBAb/2wlRspYL6EhNN6P7q3Tp06KT9/f5UtG6HR4yaqZq30d9oD9wLXpPV4uMb9FIqKitKuXbuc2nbv3q2wsLBM95HlGyq8vb21c+fOLN+58U8eHh46ceKEChYsKA8PD9lsNmUUhs1mu6M7ZnlCBVwRN1QAwK2ZeUPFO9/9lWN9j2heLtPHbty4UbVq1VJsbKxatmypDRs2qFOnTho3bpzatGmTqT6y/DM+8MAD2r9//10ldwcOHFCBAgUcfwYAADCTq1TuHnzwQc2bN0/R0dEaMGCASpYsqREjRmQ6sZPuILn74IMP1KNHDw0cOFDVq1eXr6+v0+cBAQG37eOfpcWslBkBAACsrmnTpmratOkdn5/prVAGDBigS5cu6cknn9SWLVv09NNPq2jRogoODlZwcLCCgoLuaB3elClTtHDhQsf7Xr16KSgoSLVq1dKhQ4ey3B8AAEBW2Wy2HHvd8++S2TV3uXLlUnx8vHbuvPUmf3XqZG1dUUREhEaPHq3HH39c69evV/369TVixAgtWLBAuXPn1ty5c7PUn8SaO7gm1twBwK2Zuebu3R923f6gO/Rps4gc6zsjmf4Zr+eAWU3ebufIkSMK/7/dvOfPn6/nnntOr732mqKiolS3bt1sHQsAACAjrrLmLjtk6QkVOVFa9PPz0+nT1zbJXbJkiRo2bCjp2l25ly9fzvbxAAAArCxLBdCyZcveNsHL6rNlGzZsqI4dO6pq1aravXu3nnzySUnSjh07VKJEiSz1BQAAcCdMWBqXY7KU3MXGxqZ7QsXd+uKLL9S3b18dPnxYc+bMUb58+SRJmzZt0osvvpitYwEAAGTEw0LZXZaSu1atWqlgwYLZNvjVq1f12WefqXfv3ipatKjTZ7Gxsdk2DgAAgLvI9Jq7nFhvlzt3bn300Ue6evVqtvcNAACQWR45+LrXMj1mFp9Slmn169fXL7+wdQkAAEB2yPS0bFpaWo4E0KRJE/Xp00fbtm3L8IkXTz/9dI6MCwAAcJ2Fltxl/fFj2a1z586SpGHDhqX7zGazKTU19V6HBAAAcN8yPbnLqYogAABAZlnpblkz1vnd1JUrV8wOAQAA4L5menKXmpqqgQMHqkiRIvLz89P+/fslSX379tXEiRNNjg4AALgDmy3nXvea6cndoEGDNHnyZH300Ufy8vJytD/wwAOaMGGCiZEBAAB34WHLudc9/y73fkhnU6dO1bhx49SmTRvlypXL0V6lShX99ddfJkYGAABw/zH9hopjx44pPDw8XXtaWppSUlJMiAgAALgbbqjIRhUqVNDq1avTtc+ePVtVq1Y1ISIAAID7l+mVu379+qlt27Y6duyY0tLSNHfuXO3atUtTp07VggULzA4PAAC4AQsV7syv3DVv3lw//PCDli1bJl9fX/Xr1087d+7UDz/8oIYNG5odHgAAwH3F9Mpdx44d9dJLL2np0qVmhwIAANyUGXe15hTTK3enTp3SE088oWLFiqlXr17asmWL2SEBAADct0xP7r777jvFx8erb9++2rBhg6pVq6aKFSvqww8/1MGDB80ODwAAuAFbDv5zr5me3ElScHCwXnvtNa1cuVKHDh1Su3btNG3atAy3SAEAAMhubGKcQ1JSUvT777/rt99+08GDB1WoUCGzQwIAALivuERy9/PPP6tTp04qVKiQ2rVrp4CAAC1YsEBHjx41OzQAAOAGrFS5M/1u2SJFiighIUFPPPGExo0bp2bNmslut5sdFgAAwH3J9OQuJiZGzz//vIKCgswOBQAAuCmbhXYxNj2569Spk9khAAAAWIbpyR0AAIDZ2MQYAAAALonKHQAAcHsWWnJHcgcAAOBhoeyOaVkAAAALoXIHAADcHjdUAAAAwCVRuQMAAG7PQkvuqNwBAABYCZU7AADg9jxkndIdlTsAAAALoXIHAADcnpXW3JHcAQAAt8dWKAAAAHBJVO4AAIDb4/FjAAAAcElU7gAAgNuzUOGOyh0AAICVULkDAABujzV3AAAAcElU7gAAgNuzUOGO5A4AAMBKU5lW+i4AAABuj8odAABwezYLzctSuQMAALAQKncAAMDtWaduR+UOAADAUqjcAQAAt8cmxgAAAHBJVO4AAIDbs07djuQOAADAUk+oYFoWAADAQqjcAQAAt8cmxgAAAHBJVO4AAIDbs1K1y0rfBQAAwO1RuQMAAG6PNXcAAADIdjExMbLZbE6vcuXKZakPKncAAMDtuVLdrmLFilq2bJnjfe7cWUvXSO4AAABcSO7cuVW4cOE7Pz8bYwEAALgv5eSau6SkJCUlJTm12e122e32DI/fs2ePQkND5e3trZo1a2rw4MEqXrx4psezGYZh3FXELmj2lnizQwAAl9e0YojZIQBOvE0sOc3Nwdxh67yxio2NdWrr37+/YmJi0h27aNEiXbx4UREREYqPj1dsbKyOHTum7du3y9/fP1PjkdwBgJsiuYOrsWpy91S5vFmq3P3T2bNnFRYWpmHDhunVV1/N1HhMywIAALeXk9OymU3kMhIUFKSyZctq7969mT6HrVAAAABc1MWLF7Vv3z6FhGS+0k5yBwAA3J4tB19Z0aNHD/3yyy86ePCg1q1bp2effVa5cuXSiy++mOk+mJYFAABwEUePHtWLL76o06dPq0CBAnr00Uf166+/qkCBApnug+QOAAC4PVd5+tjXX399130wLQsAAGAhVO4AAIDb83CpB5DdHZI7AADg9lxlWjY7MC0LAABgIVTuAACA27NZaFqWyh0AAICFULkDAABujzV3AAAAcElU7gAAgNuz0lYoVO4AAAAshModAABwe1Zac0dyBwAA3J6VkjumZQEAACyEyh0AAHB7bGIMAAAAl0TlDgAAuD0P6xTuqNwBAABYCZU7AADg9lhzBwAAAJdE5Q4AALg9K+1zR3IHAADcHtOyAAAAcElU7gAAgNtjKxQAAAC4JCp3AADA7bHmDgAAAC6Jyh0AAHB7VtoKhcodAACAhVC5AwAAbs9ChTuSOwAAAA8LzcsyLQsAAGAhVO4AAIDbs07djsodAACApVC5AwAAsFDpjsodAACAhVC5AwAAbo/HjwEAAMAlUbkDAABuz0Lb3JHcAQAAWCi3Y1oWAADASqjcAQAAWKh0R+UOAADAQqjcAQAAt8dWKAAAAHBJplfuUlNTNXz4cM2aNUuHDx9WcnKy0+cJCQkmRQYAANyFlbZCMb1yFxsbq2HDhumFF17QuXPn1L17d7Vo0UIeHh6KiYkxOzwAAID7iunJ3fTp0zV+/Hi9++67yp07t1588UVNmDBB/fr106+//mp2eAAAwA3YcvB1r5me3J04cUKVKlWSJPn5+encuXOSpKZNm2rhwoVmhgYAANyFhbI705O7okWLKj4+XpJUunRpLVmyRJK0ceNG2e12M0MDAAC475ie3D377LNavny5JOmtt95S3759VaZMGb3yyivq0KGDydEBAAB3YMvBf+75dzEMw7jno97Cr7/+qnXr1qlMmTJq1qzZHfUxe0t8NkcFANbTtGKI2SEATrxN3MNj86ELOdZ31TD/HOs7I6ZvhXKjRx55RI888ojZYQAAADfCVijZaPDgwfryyy/TtX/55ZcaOnSoCREBAADcv0xP7saOHaty5cqla69YsaLGjBljQkQAAMDdWOhmWfOTuxMnTigkJP26jwIFCjjuogUAAEDmmJ7cFStWTGvXrk3XvnbtWoWGhpoQEQAAcDsWKt2ZfkNFp06d9M477yglJUWPP/64JGn58uXq1auX3n33XZOjAwAA7sCMLUtyiunJXc+ePXX69Gl17txZycnJkiRvb2/17t1b0dHRJkcHAABwf3GZfe4uXryonTt3ysfHR2XKlLmrp1Owzx0A3B773MHVmLnP3bajF3Os70pF/XKs74yYXrm7zs/PTw8++KDZYQAAANzXTEnuWrRoocmTJysgIEAtWrS45bFz5869R1EBAAB3ZZ0VdyYld4GBgbL931bQgYGBZoQAAABgSS6z5i47seYOAG6PNXdwNWauudt+LOfW3D1Q5N6uuTN9nzsAAABkH9NvqPj777/Vo0cPLV++XCdPntSNhcTU1FSTInNfy2dN0orZU5za8ocWU7cR00yKCO6OaxKuZtbXMzTrm5k6fuyYJKl0eBm9/kZnPVq7jsmR4U6xz102ateunQ4fPqy+ffsqJCTEsRYP5ipYrIQ69P3U8d7DI5eJ0QBck3AtBQsV1tvdeqh4WJgMw9AP383X213e1Ddz5ik8vIzZ4cHNmZ7crVmzRqtXr1ZkZKTZoeAfPDxyyT8on9lhAA5ck3Aldes97vT+rbe7adbXM7V1SxzJ3X3KVWtLQ4YMUXR0tN5++22NGDEiU+eYntwVK1Ys3VQszHf6xDENef1fyu3ppeJlK6pR604Kyl/I7LDgxrgm4apSU1O1ZPFPunw5UVWqVDU7HNwhV8ztNm7cqLFjx6py5cpZOs/0GypGjBihPn366ODBg2aHgv9TtEwF/atzH7X7z0dq3rGbzpyM1/h+XZV0OdHs0OCmuCbhivbs3qVHalTVg1UradCA/hr+2RcqHR5udliwiIsXL6pNmzYaP368goODs3Su6VuhBAcHKzExUVevXlWePHnk6enp9HlCQsItz09KSlJSUpJT28JdCfL0uvPHl8HZ5UsX9HHnVnqybWfVePwps8MBuCazCVuh3J2U5GTFx8fr4sULWrpksebN+VYTJ39FgncXzNwKZWf8pRzru1Te3OlyFbvdfstHrbZt21Z58+bV8OHDVbduXUVGRt4/07KZDfRmBg8erNjYWKe251/vrpZv9LirfvH/+fj6K39oUZ0+cczsUABJXJNwDZ5eXioeFiZJqlDxAe3Yvk3Tv5qqfjEDTI4MriajXKV///6KiYnJ8Pivv/5af/zxhzZu3HhH45me3LVt2/auzo+Ojlb37t2d2hbuunW1D1mTdCVRCSeOK7J2I7NDASRxTcI1paWlKSU52ewwcIdyciuUjHKVm1Xtjhw5orfffltLly6Vt7f3HY1nSnJ3/vx5BQQEOP58K9ePu5mMypqeXjlXWnUHi6b+V+Vq1FJQ/kI6f+a0ls+aJJuHh6o8Wt/s0OCmuCbhakYO/1SP1n5MhUNClHjpkn5cuEC/b9yg0eMmmh0aXNDtpmD/adOmTTp58qSqVavmaEtNTdWqVav0+eefKykpSbly3XorKFOSu+DgYMXHx6tgwYIKCgrKcG87wzBks9nYxNgE5xJO6ZuRA5V44bx8AwIVVq6S/j3ov/INCDI7NLgprkm4moSE03o/urdOnTopP39/lS0bodHjJqpmrSizQ8MdcpWtUOrXr69t27Y5tbVv317lypVT7969b5vYSSYldytWrFDevHklST///LMZIeAWWr3T3+wQACdck3A1sQM/NDsEWJS/v78eeOABpzZfX1/ly5cvXfvNmJLc1alTJ8M/AwAAmMFFCnfZwvQbKrZu3Zphu81mk7e3t4oXL57peWoAAIA74sLZ3cqVK7N0vOnJXWRk5C2fJ+vp6akXXnhBY8eOveO7RgAAANyF6U+omDdvnsqUKaNx48YpLi5OcXFxGjdunCIiIjRjxgxNnDhRK1as0Pvvv292qAAAwKJsOfjPvWZ65W7QoEEaOXKkGjdu7GirVKmSihYtqr59+2rDhg3y9fXVu+++q08++cTESAEAAFyf6cndtm3bFPZ/O3z/U1hYmONW4MjISMXHx9/r0AAAgJtwla1QsoPp07LlypXTkCFDlPyPXb1TUlI0ZMgQlStXTpJ07NgxFSpUyKwQAQAA7humV+6++OILPf300ypatKgqV64s6Vo1LzU1VQsWLJAk7d+/X507dzYzTAAAYGEWKtzJZhiGYXYQFy5c0PTp07V7925JUkREhFq3bi1/f/876m/2FqZwAeB2mlYMMTsEwIm3iSWnfScv51jfpQv65FjfGTG1cpeSkqJy5cppwYIF+ve//21mKAAAwJ1ZqHRnanLn6empK1eumBkCAACAKVuW5BTTb6h48803NXToUF29etXsUAAAAO57pt9QsXHjRi1fvlxLlixRpUqV5Ovr6/T53LlzTYoMAAC4CytthWJ6chcUFKR//etfZocBAABgCaYnd5MmTTI7BAAA4OYsVLgzf80dAAAAso8plbtq1app+fLlCg4OVtWqVWW7xUT3H3/8cQ8jAwAAbslCpTtTkrvmzZvLbrdLkp555hkzQgAAALAkU5K7/v37O/585MgRtWnTRvXq1TMjFAAAAPa5y06nTp1SkyZNVKxYMfXq1UtbtmwxOyQAAOBmbLace91rpid33333neLj49W3b19t2LBB1apVU8WKFfXhhx/q4MGDZocHAABwX7EZhmGYHcQ/HT16VDNnztSXX36pPXv23NGTK2Zvic+ByADAWppWDDE7BMCJt4kbtB1JSMqxvovltedY3xkxvXL3TykpKfr999/122+/6eDBgypUqJDZIQEAANxXXCK5+/nnn9WpUycVKlRI7dq1U0BAgBYsWKCjR4+aHRoAAHADVlpzZ/oTKooUKaKEhAQ98cQTGjdunJo1a+bYJgUAAABZY3pyFxMTo+eff15BQUFmhwIAANyWdbZCMT2569Spk9khAAAAWIbpyR0AAIDZzFgbl1NI7gAAgNuzUG7nGnfLAgAAIHtQuQMAAG7PStOyVO4AAAAshModAABwezYLrbqjcgcAAGAhVO4AAACsU7ijcgcAAGAlVO4AAIDbs1DhjuQOAACArVAAAADgkqjcAQAAt8dWKAAAAHBJVO4AAACsU7ijcgcAAGAlVO4AAIDbs1DhjsodAACAlVC5AwAAbs9K+9yR3AEAALfHVigAAABwSVTuAACA27PStCyVOwAAAAshuQMAALAQkjsAAAALYc0dAABwe6y5AwAAgEuicgcAANyelfa5I7kDAABuj2lZAAAAuCQqdwAAwO1ZqHBH5Q4AAMBKqNwBAABYqHRH5Q4AAMBCqNwBAAC3Z6WtUKjcAQAAWAiVOwAA4PbY5w4AAAAuicodAABwexYq3JHcAQAAWCm7Y1oWAADAQkjuAACA27Pl4D9ZMXr0aFWuXFkBAQEKCAhQzZo1tWjRoiz1QXIHAADgIooWLaohQ4Zo06ZN+v333/X444+refPm2rFjR6b7sBmGYeRgjKaYvSXe7BAAwOU1rRhidgiAE28T7wS4cjXn+r7b75U3b159/PHHevXVVzN1PDdUAAAA5KCkpCQlJSU5tdntdtnt9luel5qaqm+//VaXLl1SzZo1Mz2eJSt3yB5JSUkaPHiwoqOjb3sBAvcC1yRcEdclbicmJkaxsbFObf3791dMTEyGx2/btk01a9bUlStX5OfnpxkzZujJJ5/M9Hgkd7ip8+fPKzAwUOfOnVNAQIDZ4QBck3BJXJe4naxW7pKTk3X48GGdO3dOs2fP1oQJE/TLL7+oQoUKmRqPaVkAAIAclJkp2H/y8vJSeHi4JKl69erauHGjRo4cqbFjx2bqfO6WBQAAcGFpaWnpKn+3QuUOAADARURHR6tJkyYqXry4Lly4oBkzZmjlypVavHhxpvsgucNN2e129e/fnwXCcBlck3BFXJfITidPntQrr7yi+Ph4BQYGqnLlylq8eLEaNmyY6T64oQIAAMBCWHMHAABgISR3AAAAFkJyBwAAYCEkdwBc2sGDB2Wz2RQXF+eS/eH+EhMTo8jIyLvuZ+XKlbLZbDp79mymz2nXrp2eeeaZux4buB1uqIAOHjyokiVLavPmzdnylx6QnVJTU3Xq1Cnlz59fuXPf/Q3+XO/u7eLFi0pKSlK+fPnuqp/k5GQlJCSoUKFCstlsmTrn3LlzMgxDQUFBdzU2cDtshQLAVCkpKfL09Lzp57ly5VLhwoXvYUS3l5ycLC8vL7PDwB3w8/OTn5/fTT/P7P+2Xl5eWb4uAwMDs3Q8cKeYlrWQ2bNnq1KlSvLx8VG+fPnUoEEDXbp0SZI0YcIElS9fXt7e3ipXrpz++9//Os4rWbKkJKlq1aqy2WyqW7eupGs7Yg8YMEBFixaV3W5XZGSkfvrpJ8d5ycnJ6tKli0JCQuTt7a2wsDANHjzY8fmwYcNUqVIl+fr6qlixYurcubMuXrx4D34J5JRx48YpNDRUaWlpTu3NmzdXhw4dJEnfffedqlWrJm9vb5UqVUqxsbG6evWq41ibzabRo0fr6aeflq+vrwYNGqQzZ86oTZs2KlCggHx8fFSmTBlNmjRJUsbTqDt27FDTpk0VEBAgf39/1a5dW/v27ZN0++s2I7/88oseeugh2e12hYSEqE+fPk4x161bV126dNE777yj/Pnzq3Hjxnf1OyLn3O4avXFa9vpU6aBBgxQaGqqIiAhJ0rp16xQZGSlvb2/VqFFD8+fPd7oOb5yWnTx5soKCgrR48WKVL19efn5+euKJJxQfH59urOvS0tL00UcfKTw8XHa7XcWLF9egQYMcn/fu3Vtly5ZVnjx5VKpUKfXt21cpKSnZ+4PBmgxYwvHjx43cuXMbw4YNMw4cOGBs3brV+OKLL4wLFy4YX331lRESEmLMmTPH2L9/vzFnzhwjb968xuTJkw3DMIwNGzYYkoxly5YZ8fHxxunTpw3DMIxhw4YZAQEBxsyZM42//vrL6NWrl+Hp6Wns3r3bMAzD+Pjjj41ixYoZq1atMg4ePGisXr3amDFjhiOm4cOHGytWrDAOHDhgLF++3IiIiDDeeOONe//jINskJCQYXl5exrJlyxxtp0+fdrStWrXKCAgIMCZPnmzs27fPWLJkiVGiRAkjJibGcbwko2DBgsaXX35p7Nu3zzh06JDx5ptvGpGRkcbGjRuNAwcOGEuXLjW+//57wzAM48CBA4YkY/PmzYZhGMbRo0eNvHnzGi1atDA2btxo7Nq1y/jyyy+Nv/76yzCM21+3GfWXJ08eo3PnzsbOnTuNefPmGfnz5zf69+/viLlOnTqGn5+f0bNnT+Ovv/5yjAXXc7trtH///kaVKlUcn7Vt29bw8/MzXn75ZWP79u3G9u3bjXPnzhl58+Y1XnrpJWPHjh3Gjz/+aJQtW9bpuvn5558NScaZM2cMwzCMSZMmGZ6enkaDBg2MjRs3Gps2bTLKly9vtG7d2mms5s2bO9736tXLCA4ONiZPnmzs3bvXWL16tTF+/HjH5wMHDjTWrl1rHDhwwPj++++NQoUKGUOHDs2R3w3WQnJnEZs2bTIkGQcPHkz3WenSpZ2SLsO49pdGzZo1DcNI/y+760JDQ41BgwY5tT344ING586dDcMwjLfeest4/PHHjbS0tEzF+O233xr58uXL7FeCi2revLnRoUMHx/uxY8caoaGhRmpqqlG/fn3jww8/dDp+2rRpRkhIiOO9JOOdd95xOqZZs2ZG+/btMxzvxuszOjraKFmypJGcnJzh8be7bm/s7z//+Y8RERHhdB1/8cUXhp+fn5GammoYxrXkrmrVqjf7SeBibnWNZpTcFSpUyEhKSnK0jR492siXL59x+fJlR9v48eNvm9xJMvbu3es454svvjAKFSrkNNb15O78+fOG3W53SuZu5+OPPzaqV6+e6ePhvpiWtYgqVaqofv36qlSpkp5//nmNHz9eZ86c0aVLl7Rv3z69+uqrjrUmfn5++uCDDxzTWBk5f/68jh8/rqioKKf2qKgo7dy5U9K1KYa4uDhFRESoa9euWrJkidOxy5YtU/369VWkSBH5+/vr5Zdf1unTp5WYmJj9PwDumTZt2mjOnDmOh1hPnz5drVq1koeHh7Zs2aIBAwY4XWudOnVSfHy80//uNWrUcOrzjTfe0Ndff63IyEj16tVL69atu+n4cXFxql27dobr9DJz3d5o586dqlmzptOi+KioKF28eFFHjx51tFWvXv0Wvwpcya2u0YxUqlTJaZ3drl27VLlyZXl7ezvaHnrooduOmydPHpUuXdrxPiQkRCdPnszw2J07dyopKUn169e/aX/ffPONoqKiVLhwYfn5+en999/X4cOHbxsHQHJnEbly5dLSpUu1aNEiVahQQaNGjVJERIS2b98uSRo/frzi4uIcr+3bt+vXX3+9qzGrVaumAwcOaODAgbp8+bJatmyp5557TtK1dVJNmzZV5cqVNWfOHG3atElffPGFpGtr9XD/atasmQzD0MKFC3XkyBGtXr1abdq0kXTtTsTY2Fina23btm3as2eP078ofX19nfps0qSJDh06pG7duun48eOqX7++evTokeH4Pj4+OfflbuHGmOG6bnWNZiS7/re98T84bDabjJtsSHG763j9+vVq06aNnnzySS1YsECbN2/We++9x9+fyBSSOwux2WyKiopSbGysNm/eLC8vL61du1ahoaHav3+/wsPDnV7Xb6S4/l+sqampjr4CAgIUGhqqtWvXOo2xdu1aVahQwem4F154QePHj9c333yjOXPmKCEhQZs2bVJaWpo+/fRTPfLIIypbtqyOHz9+D34F5DRvb2+1aNFC06dP18yZMxUREaFq1apJupbw79q1K921Fh4eftOqyXUFChRQ27Zt9dVXX2nEiBEaN25chsdVrlxZq1evznBheWav238qX7681q9f7/Qv4bVr18rf319Fixa9ZcxwTbe6RjMjIiJC27Ztc1T+JGnjxo3ZGmOZMmXk4+Oj5cuXZ/j5unXrFBYWpvfee081atRQmTJldOjQoWyNAdbFVigW8dtvv2n58uVq1KiRChYsqN9++02nTp1S+fLlFRsbq65duyowMFBPPPGEkpKS9Pvvv+vMmTPq3r27ChYsKB8fH/30008qWrSovL29FRgYqJ49e6p///4qXbq0IiMjNWnSJMXFxWn69OmSrt0NGxISoqpVq8rDw0PffvutChcurKCgIIWHhyslJUWjRo1Ss2bNtHbtWo0ZM8bkXwnZpU2bNmratKl27Nihl156ydHer18/NW3aVMWLF9dzzz3nmKrdvn27Pvjgg5v2169fP1WvXl0VK1ZUUlKSFixYoPLly2d4bJcuXTRq1Ci1atVK0dHRCgwM1K+//qqHHnpIERERt71ub9S5c2eNGDFCb731lrp06aJdu3apf//+6t69+20TUrium12jmdG6dWu99957eu2119SnTx8dPnxYn3zyiSRlek+72/H29lbv3r3Vq1cveXl5KSoqSqdOndKOHTv06quvqkyZMjp8+LC+/vprPfjgg1q4cKHmzZuXLWPDDZi75A/Z5c8//zQaN25sFChQwLDb7UbZsmWNUaNGOT6fPn26ERkZaXh5eRnBwcHGY489ZsydO9fx+fjx441ixYoZHh4eRp06dQzDMIzU1FQjJibGKFKkiOHp6WlUqVLFWLRokeOccePGGZGRkYavr68REBBg1K9f3/jjjz8cnw8bNswICQkxfHx8jMaNGxtTp051WoCM+1dqaqoREhJiSDL27dvn9NlPP/1k1KpVy/Dx8TECAgKMhx56yBg3bpzjc0nGvHnznM4ZOHCgUb58ecPHx8fImzev0bx5c2P//v2GYWR8w8+WLVuMRo0aGXny5DH8/f2N2rVrO+K43XWbUX8rV640HnzwQcPLy8soXLiw0bt3byMlJcXxeZ06dYy33377Ln813Es3u0YzuqHin3ewXrd27VqjcuXKhpeXl1G9enVjxowZhiTHndIZ3VARGBjo1Me8efOMf/5r9saxUlNTjQ8++MAICwszPD09jeLFizvdkNSzZ08jX758hp+fn/HCCy8Yw4cPTzcGkBGeUAEAwG1Mnz5d7du317lz50xb9wlkFtOyAADcYOrUqSpVqpSKFCmiLVu2qHfv3mrZsiWJHe4LJHcAANzgxIkT6tevn06cOKGQkBA9//zzTk+PAFwZ07IAAAAWwq1gAAAAFkJyBwAAYCEkdwAAABZCcgcAAGAhJHcAAAAWQnIHwGW1a9dOzzzzjON93bp19c4779zzOFauXCmbzaazZ8/e87EBIKtI7gBkWbt27WSz2WSz2eTl5aXw8HANGDBAV69ezdFx586dq4EDB2bqWBIyAO6KTYwB3JEnnnhCkyZNUlJSkn788Ue9+eab8vT0VHR0tNNxycnJ8vLyypYx8+bNmy39AICVUbkDcEfsdrsKFy6ssLAwvfHGG2rQoIG+//57x1TqoEGDFBoaqoiICEnSkSNH1LJlSwUFBSlv3rxq3ry5Dh486OgvNTVV3bt3V1BQkPLly6devXrpxj3Wb5yWTUpKUu/evVWsWDHZ7XaFh4dr4sSJOnjwoOrVqydJCg4Ols1mU7t27SRJaWlpGjx4sEqWLCkfHx9VqVJFs2fPdhrnxx9/VNmyZeXj46N69eo5xQkAro7kDkC28PHxUXJysiRp+fLl2rVrl5YuXaoFCxYoJSVFjRs3lr+/v1avXq21a9fKz89PTzzxhOOcTz/9VJMnT9aXX36pNWvWKCEhQfPmzbvlmK+88opmzpypzz77TDt37tTYsWPl5+enYsWKac6cOZKkXbt2KT4+XiNHjpQkDR48WFOnTtWYMWO0Y8cOdevWTS+99JJ++eUXSdeS0BYtWqhZs2aKi4tTx44d1adPn5z62QAg2zEtC+CuGIah5cuXa/HixXrrrbd06tQp+fr6asKECY7p2K+++kppaWmaMGGCbDabJGnSpEkKCgrSypUr1ahRI40YMULR0dFq0aKFJGnMmDFavHjxTcfdvXu3Zs2apaVLl6pBgwaSpFKlSjk+vz6FW7BgQQUFBUm6Vun78MMPtWzZMtWsWdNxzpo1azR27FjVqVNHo0ePVunSpfXpp59KkiIiIrRt2zYNHTo0G381AMg5JHcA7siCBQvk5+enlJQUpaWlqXXr1oqJidGbb76pSpUqOa2z27Jli/bu3St/f3+nPq5cuaJ9+/bp3Llzio+P18MPP+z4LHfu3KpRo0a6qdnr4uLilCtXLtWpUyfTMe/du1eJiYlq2LChU3tycrKqVq0qSdq5c6dTHJIciSAA3A9I7gDckXr16mn06NHy8vJSaGiocuf+/3+d+Pr6Oh178eJFVa9eXdOnT0/XT4ECBe5ofB8fnyyfc/HiRUnSwoULVaRIEafP7Hb7HcUBAK6G5A7AHfH19VV4eHimjq1WrZq++eYbFSxYUAEBARkeExISot9++02PPfaYJOnq1avatGmTqlWrluHxlSpVUlpamn755RfHtOw/Xa8cpqamOtoqVKggu92uw4cP37TiV758eX3//fdObb/++uvtvyQAuAhuqACQ49q0aaP8+fOrefPmWr16tQ4cOKCVK1eqa9euOnr0qCTp7bff1pAhQzR//nz99ddf6ty58y33qCtRooTatm2rDh06aP78+Y4+Z82aJUkKCwuTzWbTggULdOrUKV28eFH+/v7q0aOHunXrpilTpmjfvn36448/NGrUKE2ZMkWS9O9//1t79uxRz549tWvXLs2YMUOTJ0/O6Z8IALINyR2AHJcnTx6tWrVKxYsXV4sWLVS+fHm9+uqrunLliqOS9+677+rll19W27ZtVbNmTfn7++vZZ5+9Zb+jR4/Wc889p86dO6tcuXLq1KmTLl26JEkqUqSIYmNj1adPHxUqVEhdunSRJA0cOFB9+/bV4MGDVb58eT3xxBNauHChSpYsKUkqXry45syZo/nz56tKlSoaM2aMPvzwwxz8dQAge9mMm61WBgAAwH2Hyh0AAICFkNwBAABYCMkdAACAhZDcAQAAWAjJHQAAgIWQ3AEAAFgIyR0AAICFkNwBAABYCMkdAACAhZDcAQAAWAjJHQAAgIX8P8k6iTm6sjVlAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q30.Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, 6],  # Example depth values\n",
        "    'min_samples_split': [2, 5, 10]  # Example minimum samples\n",
        "}\n",
        "\n",
        "# Create a Decision Tree Classifier\n",
        "dtc = DecisionTreeClassifier()\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=dtc, param_grid=param_grid, cv=5, scoring='accuracy') # 5-fold cross-validation\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Score:\", grid_search.best_score_)\n",
        "\n",
        "# Get the best model\n",
        "best_dtc = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "accuracy = best_dtc.score(X_test, y_test)\n",
        "print(f\"Accuracy on test set with best parameters: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vtA1F2a53C-",
        "outputId": "a12c705e-b467-4fcb-add7-de778a796a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 10}\n",
            "Best Score: 0.9428571428571428\n",
            "Accuracy on test set with best parameters: 1.0\n"
          ]
        }
      ]
    }
  ]
}